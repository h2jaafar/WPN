[2019-06-02 20:02:52] - Starting holdout training: {
	data_features: [],
	data_labels: [],
	data_single_features: ['global_map'],
	data_single_labels: ['global_map'],
	epochs: 100,
	loss: L1Loss(),
	optimizer: <function f.<locals>.<lambda> at 0x7f819e27b378>,
	validation_ratio: 0.2,
	test_ratio: 0.2,
	save_name: caelstm_section_cae,
	training_data: ['training_uniform_random_fill_10000'],
	batch_size: 50,
	use_mnist_instead: False,
	mnist_size: None,
	with_skip_connections: True,
	in_dim: [64, 64],
	latent_dim: 100,
}

[2019-06-02 20:02:52] - Starting data pre processing
[2019-06-02 20:02:53] - Cache hit, training data loaded from cache
[2019-06-02 20:02:53] - Finished data pre processing 

[2019-06-02 20:02:53] - Training: <class 'algorithms.lstm.LSTM_CAE_tile_by_tile.CAE'>
[2019-06-02 20:02:55] - Training 	 Epoch: 0 	 Loss: 0.039653
[2019-06-02 20:02:56] - Validation 	 Epoch: 0 	 Loss: 0.118060

[2019-06-02 20:02:59] - Training 	 Epoch: 1 	 Loss: 0.015204
[2019-06-02 20:03:00] - Validation 	 Epoch: 1 	 Loss: 0.045413

[2019-06-02 20:03:02] - Training 	 Epoch: 2 	 Loss: 0.008433
[2019-06-02 20:03:03] - Validation 	 Epoch: 2 	 Loss: 0.025078

[2019-06-02 20:03:05] - Training 	 Epoch: 3 	 Loss: 0.005486
[2019-06-02 20:03:06] - Validation 	 Epoch: 3 	 Loss: 0.015916

[2019-06-02 20:03:09] - Training 	 Epoch: 4 	 Loss: 0.003903
[2019-06-02 20:03:10] - Validation 	 Epoch: 4 	 Loss: 0.011531

[2019-06-02 20:03:12] - Training 	 Epoch: 5 	 Loss: 0.002940
[2019-06-02 20:03:13] - Validation 	 Epoch: 5 	 Loss: 0.008497

[2019-06-02 20:03:15] - Training 	 Epoch: 6 	 Loss: 0.002304
[2019-06-02 20:03:16] - Validation 	 Epoch: 6 	 Loss: 0.006627

[2019-06-02 20:03:18] - Training 	 Epoch: 7 	 Loss: 0.001859
[2019-06-02 20:03:19] - Validation 	 Epoch: 7 	 Loss: 0.005400

[2019-06-02 20:03:22] - Training 	 Epoch: 8 	 Loss: 0.001534
[2019-06-02 20:03:23] - Validation 	 Epoch: 8 	 Loss: 0.004411

[2019-06-02 20:03:25] - Training 	 Epoch: 9 	 Loss: 0.001288
[2019-06-02 20:03:26] - Validation 	 Epoch: 9 	 Loss: 0.003685

[2019-06-02 20:03:29] - Training 	 Epoch: 10 	 Loss: 0.001097
[2019-06-02 20:03:30] - Validation 	 Epoch: 10 	 Loss: 0.003157

[2019-06-02 20:03:32] - Training 	 Epoch: 11 	 Loss: 0.000945
[2019-06-02 20:03:33] - Validation 	 Epoch: 11 	 Loss: 0.002729

[2019-06-02 20:03:35] - Training 	 Epoch: 12 	 Loss: 0.000822
[2019-06-02 20:03:36] - Validation 	 Epoch: 12 	 Loss: 0.002364

[2019-06-02 20:03:39] - Training 	 Epoch: 13 	 Loss: 0.000721
[2019-06-02 20:03:40] - Validation 	 Epoch: 13 	 Loss: 0.002041

[2019-06-02 20:03:42] - Training 	 Epoch: 14 	 Loss: 0.000637
[2019-06-02 20:03:43] - Validation 	 Epoch: 14 	 Loss: 0.001817

[2019-06-02 20:03:45] - Training 	 Epoch: 15 	 Loss: 0.000567
[2019-06-02 20:03:46] - Validation 	 Epoch: 15 	 Loss: 0.001618

[2019-06-02 20:03:49] - Training 	 Epoch: 16 	 Loss: 0.000506
[2019-06-02 20:03:50] - Validation 	 Epoch: 16 	 Loss: 0.001440

[2019-06-02 20:03:52] - Training 	 Epoch: 17 	 Loss: 0.000455
[2019-06-02 20:03:53] - Validation 	 Epoch: 17 	 Loss: 0.001293

[2019-06-02 20:03:55] - Training 	 Epoch: 18 	 Loss: 0.000410
[2019-06-02 20:03:56] - Validation 	 Epoch: 18 	 Loss: 0.001162

[2019-06-02 20:03:59] - Training 	 Epoch: 19 	 Loss: 0.000371
[2019-06-02 20:04:00] - Validation 	 Epoch: 19 	 Loss: 0.001049

[2019-06-02 20:04:02] - Training 	 Epoch: 20 	 Loss: 0.000337
[2019-06-02 20:04:03] - Validation 	 Epoch: 20 	 Loss: 0.000949

[2019-06-02 20:04:05] - Training 	 Epoch: 21 	 Loss: 0.000307
[2019-06-02 20:04:06] - Validation 	 Epoch: 21 	 Loss: 0.000865

[2019-06-02 20:04:09] - Training 	 Epoch: 22 	 Loss: 0.000280
[2019-06-02 20:04:10] - Validation 	 Epoch: 22 	 Loss: 0.000789

[2019-06-02 20:04:12] - Training 	 Epoch: 23 	 Loss: 0.000257
[2019-06-02 20:04:13] - Validation 	 Epoch: 23 	 Loss: 0.000723

[2019-06-02 20:04:15] - Training 	 Epoch: 24 	 Loss: 0.000235
[2019-06-02 20:04:16] - Validation 	 Epoch: 24 	 Loss: 0.000663

[2019-06-02 20:04:19] - Training 	 Epoch: 25 	 Loss: 0.000216
[2019-06-02 20:04:20] - Validation 	 Epoch: 25 	 Loss: 0.000606

[2019-06-02 20:04:22] - Training 	 Epoch: 26 	 Loss: 0.000199
[2019-06-02 20:04:23] - Validation 	 Epoch: 26 	 Loss: 0.000556

[2019-06-02 20:04:25] - Training 	 Epoch: 27 	 Loss: 0.000184
[2019-06-02 20:04:26] - Validation 	 Epoch: 27 	 Loss: 0.000511

[2019-06-02 20:04:29] - Training 	 Epoch: 28 	 Loss: 0.000170
[2019-06-02 20:04:30] - Validation 	 Epoch: 28 	 Loss: 0.000473

[2019-06-02 20:04:32] - Training 	 Epoch: 29 	 Loss: 0.000157
[2019-06-02 20:04:33] - Validation 	 Epoch: 29 	 Loss: 0.000438

[2019-06-02 20:04:35] - Training 	 Epoch: 30 	 Loss: 0.000146
[2019-06-02 20:04:36] - Validation 	 Epoch: 30 	 Loss: 0.000407

[2019-06-02 20:04:39] - Training 	 Epoch: 31 	 Loss: 0.000135
[2019-06-02 20:04:40] - Validation 	 Epoch: 31 	 Loss: 0.000376

[2019-06-02 20:04:42] - Training 	 Epoch: 32 	 Loss: 0.000125
[2019-06-02 20:04:43] - Validation 	 Epoch: 32 	 Loss: 0.000349

[2019-06-02 20:04:45] - Training 	 Epoch: 33 	 Loss: 0.000117
[2019-06-02 20:04:46] - Validation 	 Epoch: 33 	 Loss: 0.000324

[2019-06-02 20:04:49] - Training 	 Epoch: 34 	 Loss: 0.000108
[2019-06-02 20:04:50] - Validation 	 Epoch: 34 	 Loss: 0.000300

[2019-06-02 20:04:52] - Training 	 Epoch: 35 	 Loss: 0.000101
[2019-06-02 20:04:53] - Validation 	 Epoch: 35 	 Loss: 0.000279

[2019-06-02 20:04:55] - Training 	 Epoch: 36 	 Loss: 0.000094
[2019-06-02 20:04:56] - Validation 	 Epoch: 36 	 Loss: 0.000259

[2019-06-02 20:04:59] - Training 	 Epoch: 37 	 Loss: 0.000088
[2019-06-02 20:05:00] - Validation 	 Epoch: 37 	 Loss: 0.000242

[2019-06-02 20:05:02] - Training 	 Epoch: 38 	 Loss: 0.000082
[2019-06-02 20:05:03] - Validation 	 Epoch: 38 	 Loss: 0.000226

[2019-06-02 20:05:06] - Training 	 Epoch: 39 	 Loss: 0.000076
[2019-06-02 20:05:06] - Validation 	 Epoch: 39 	 Loss: 0.000211

[2019-06-02 20:05:09] - Training 	 Epoch: 40 	 Loss: 0.000071
[2019-06-02 20:05:10] - Validation 	 Epoch: 40 	 Loss: 0.000197

[2019-06-02 20:05:12] - Training 	 Epoch: 41 	 Loss: 0.000067
[2019-06-02 20:05:13] - Validation 	 Epoch: 41 	 Loss: 0.000184

[2019-06-02 20:05:16] - Training 	 Epoch: 42 	 Loss: 0.000062
[2019-06-02 20:05:16] - Validation 	 Epoch: 42 	 Loss: 0.000171

[2019-06-02 20:05:19] - Training 	 Epoch: 43 	 Loss: 0.000058
[2019-06-02 20:05:20] - Validation 	 Epoch: 43 	 Loss: 0.000160

[2019-06-02 20:05:22] - Training 	 Epoch: 44 	 Loss: 0.000055
[2019-06-02 20:05:23] - Validation 	 Epoch: 44 	 Loss: 0.000150

[2019-06-02 20:05:26] - Training 	 Epoch: 45 	 Loss: 0.000051
[2019-06-02 20:05:27] - Validation 	 Epoch: 45 	 Loss: 0.000140

[2019-06-02 20:05:29] - Training 	 Epoch: 46 	 Loss: 0.000048
[2019-06-02 20:05:30] - Validation 	 Epoch: 46 	 Loss: 0.000131

[2019-06-02 20:05:32] - Training 	 Epoch: 47 	 Loss: 0.000045
[2019-06-02 20:05:33] - Validation 	 Epoch: 47 	 Loss: 0.000123

[2019-06-02 20:05:36] - Training 	 Epoch: 48 	 Loss: 0.000042
[2019-06-02 20:05:37] - Validation 	 Epoch: 48 	 Loss: 0.000115

[2019-06-02 20:05:39] - Training 	 Epoch: 49 	 Loss: 0.000040
[2019-06-02 20:05:40] - Validation 	 Epoch: 49 	 Loss: 0.000108

[2019-06-02 20:05:42] - Training 	 Epoch: 50 	 Loss: 0.000037
[2019-06-02 20:05:43] - Validation 	 Epoch: 50 	 Loss: 0.000101

[2019-06-02 20:05:46] - Training 	 Epoch: 51 	 Loss: 0.000035
[2019-06-02 20:05:47] - Validation 	 Epoch: 51 	 Loss: 0.000095

[2019-06-02 20:05:49] - Training 	 Epoch: 52 	 Loss: 0.000033
[2019-06-02 20:05:50] - Validation 	 Epoch: 52 	 Loss: 0.000089

[2019-06-02 20:05:53] - Training 	 Epoch: 53 	 Loss: 0.000031
[2019-06-02 20:05:54] - Validation 	 Epoch: 53 	 Loss: 0.000083

[2019-06-02 20:05:56] - Training 	 Epoch: 54 	 Loss: 0.000029
[2019-06-02 20:05:57] - Validation 	 Epoch: 54 	 Loss: 0.000078

[2019-06-02 20:05:59] - Training 	 Epoch: 55 	 Loss: 0.000027
[2019-06-02 20:06:00] - Validation 	 Epoch: 55 	 Loss: 0.000073

[2019-06-02 20:06:03] - Training 	 Epoch: 56 	 Loss: 0.000026
[2019-06-02 20:06:04] - Validation 	 Epoch: 56 	 Loss: 0.000069

[2019-06-02 20:06:06] - Training 	 Epoch: 57 	 Loss: 0.000024
[2019-06-02 20:06:07] - Validation 	 Epoch: 57 	 Loss: 0.000065

[2019-06-02 20:06:09] - Training 	 Epoch: 58 	 Loss: 0.000023
[2019-06-02 20:06:10] - Validation 	 Epoch: 58 	 Loss: 0.000061

[2019-06-02 20:06:13] - Training 	 Epoch: 59 	 Loss: 0.000021
[2019-06-02 20:06:14] - Validation 	 Epoch: 59 	 Loss: 0.000057

[2019-06-02 20:06:16] - Training 	 Epoch: 60 	 Loss: 0.000020
[2019-06-02 20:06:17] - Validation 	 Epoch: 60 	 Loss: 0.000053

[2019-06-02 20:06:20] - Training 	 Epoch: 61 	 Loss: 0.000019
[2019-06-02 20:06:20] - Validation 	 Epoch: 61 	 Loss: 0.000050

[2019-06-02 20:06:23] - Training 	 Epoch: 62 	 Loss: 0.000018
[2019-06-02 20:06:24] - Validation 	 Epoch: 62 	 Loss: 0.000047

[2019-06-02 20:06:26] - Training 	 Epoch: 63 	 Loss: 0.000017
[2019-06-02 20:06:27] - Validation 	 Epoch: 63 	 Loss: 0.000044

[2019-06-02 20:06:30] - Training 	 Epoch: 64 	 Loss: 0.000016
[2019-06-02 20:06:31] - Validation 	 Epoch: 64 	 Loss: 0.000042

[2019-06-02 20:06:33] - Training 	 Epoch: 65 	 Loss: 0.000015
[2019-06-02 20:06:34] - Validation 	 Epoch: 65 	 Loss: 0.000039

[2019-06-02 20:06:36] - Training 	 Epoch: 66 	 Loss: 0.000014
[2019-06-02 20:06:37] - Validation 	 Epoch: 66 	 Loss: 0.000037

[2019-06-02 20:06:40] - Training 	 Epoch: 67 	 Loss: 0.000013
[2019-06-02 20:06:41] - Validation 	 Epoch: 67 	 Loss: 0.000035

[2019-06-02 20:06:43] - Training 	 Epoch: 68 	 Loss: 0.000012
[2019-06-02 20:06:44] - Validation 	 Epoch: 68 	 Loss: 0.000033

[2019-06-02 20:06:46] - Training 	 Epoch: 69 	 Loss: 0.000012
[2019-06-02 20:06:47] - Validation 	 Epoch: 69 	 Loss: 0.000030

[2019-06-02 20:06:50] - Training 	 Epoch: 70 	 Loss: 0.000011
[2019-06-02 20:06:51] - Validation 	 Epoch: 70 	 Loss: 0.000029

[2019-06-02 20:06:53] - Training 	 Epoch: 71 	 Loss: 0.000010
[2019-06-02 20:06:54] - Validation 	 Epoch: 71 	 Loss: 0.000027

[2019-06-02 20:06:57] - Training 	 Epoch: 72 	 Loss: 0.000010
[2019-06-02 20:06:57] - Validation 	 Epoch: 72 	 Loss: 0.000025

[2019-06-02 20:07:00] - Training 	 Epoch: 73 	 Loss: 0.000009
[2019-06-02 20:07:01] - Validation 	 Epoch: 73 	 Loss: 0.000024

[2019-06-02 20:07:03] - Training 	 Epoch: 74 	 Loss: 0.000009
[2019-06-02 20:07:04] - Validation 	 Epoch: 74 	 Loss: 0.000023

[2019-06-02 20:07:07] - Training 	 Epoch: 75 	 Loss: 0.000008
[2019-06-02 20:07:08] - Validation 	 Epoch: 75 	 Loss: 0.000021

[2019-06-02 20:07:10] - Training 	 Epoch: 76 	 Loss: 0.000008
[2019-06-02 20:07:11] - Validation 	 Epoch: 76 	 Loss: 0.000020

[2019-06-02 20:07:13] - Training 	 Epoch: 77 	 Loss: 0.000007
[2019-06-02 20:07:14] - Validation 	 Epoch: 77 	 Loss: 0.000019

[2019-06-02 20:07:17] - Training 	 Epoch: 78 	 Loss: 0.000007
[2019-06-02 20:07:18] - Validation 	 Epoch: 78 	 Loss: 0.000018

[2019-06-02 20:07:20] - Training 	 Epoch: 79 	 Loss: 0.000006
[2019-06-02 20:07:21] - Validation 	 Epoch: 79 	 Loss: 0.000017

[2019-06-02 20:07:23] - Training 	 Epoch: 80 	 Loss: 0.000006
[2019-06-02 20:07:24] - Validation 	 Epoch: 80 	 Loss: 0.000016

[2019-06-02 20:07:27] - Training 	 Epoch: 81 	 Loss: 0.000006
[2019-06-02 20:07:28] - Validation 	 Epoch: 81 	 Loss: 0.000015

[2019-06-02 20:07:30] - Training 	 Epoch: 82 	 Loss: 0.000005
[2019-06-02 20:07:31] - Validation 	 Epoch: 82 	 Loss: 0.000014

[2019-06-02 20:07:34] - Training 	 Epoch: 83 	 Loss: 0.000005
[2019-06-02 20:07:34] - Validation 	 Epoch: 83 	 Loss: 0.000013

[2019-06-02 20:07:37] - Training 	 Epoch: 84 	 Loss: 0.000005
[2019-06-02 20:07:38] - Validation 	 Epoch: 84 	 Loss: 0.000012

[2019-06-02 20:07:40] - Training 	 Epoch: 85 	 Loss: 0.000004
[2019-06-02 20:07:41] - Validation 	 Epoch: 85 	 Loss: 0.000011

[2019-06-02 20:07:44] - Training 	 Epoch: 86 	 Loss: 0.000004
[2019-06-02 20:07:45] - Validation 	 Epoch: 86 	 Loss: 0.000011

[2019-06-02 20:07:47] - Training 	 Epoch: 87 	 Loss: 0.000004
[2019-06-02 20:07:48] - Validation 	 Epoch: 87 	 Loss: 0.000010

[2019-06-02 20:07:50] - Training 	 Epoch: 88 	 Loss: 0.000004
[2019-06-02 20:07:51] - Validation 	 Epoch: 88 	 Loss: 0.000010

[2019-06-02 20:07:54] - Training 	 Epoch: 89 	 Loss: 0.000004
[2019-06-02 20:07:55] - Validation 	 Epoch: 89 	 Loss: 0.000009

[2019-06-02 20:07:57] - Training 	 Epoch: 90 	 Loss: 0.000003
[2019-06-02 20:07:58] - Validation 	 Epoch: 90 	 Loss: 0.000008

[2019-06-02 20:08:01] - Training 	 Epoch: 91 	 Loss: 0.000003
[2019-06-02 20:08:01] - Validation 	 Epoch: 91 	 Loss: 0.000008

[2019-06-02 20:08:04] - Training 	 Epoch: 92 	 Loss: 0.000003
[2019-06-02 20:08:05] - Validation 	 Epoch: 92 	 Loss: 0.000008

[2019-06-02 20:08:07] - Training 	 Epoch: 93 	 Loss: 0.000003
[2019-06-02 20:08:08] - Validation 	 Epoch: 93 	 Loss: 0.000007

[2019-06-02 20:08:11] - Training 	 Epoch: 94 	 Loss: 0.000003
[2019-06-02 20:08:12] - Validation 	 Epoch: 94 	 Loss: 0.000007

[2019-06-02 20:08:14] - Training 	 Epoch: 95 	 Loss: 0.000002
[2019-06-02 20:08:15] - Validation 	 Epoch: 95 	 Loss: 0.000006

[2019-06-02 20:08:17] - Training 	 Epoch: 96 	 Loss: 0.000002
[2019-06-02 20:08:18] - Validation 	 Epoch: 96 	 Loss: 0.000006

[2019-06-02 20:08:21] - Training 	 Epoch: 97 	 Loss: 0.000002
[2019-06-02 20:08:22] - Validation 	 Epoch: 97 	 Loss: 0.000006

[2019-06-02 20:08:24] - Training 	 Epoch: 98 	 Loss: 0.000002
[2019-06-02 20:08:25] - Validation 	 Epoch: 98 	 Loss: 0.000005

[2019-06-02 20:08:27] - Training 	 Epoch: 99 	 Loss: 0.000002
[2019-06-02 20:08:28] - Validation 	 Epoch: 99 	 Loss: 0.000005


[2019-06-02 20:08:28] - Evaluation: <class 'algorithms.lstm.LSTM_CAE_tile_by_tile.CAE'>
[2019-06-02 20:08:29] - Evaluation 	 Epoch: 0 	 Loss: 0.000005

[2019-06-02 20:08:29] - Saved model as caelstm_section_cae_training_uniform_random_fill_10000_model
[2019-06-02 20:08:29] - Model: CAE(
  (encoder): CAEEncoder(
    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (latent_linear): Linear(in_features=128, out_features=100, bias=True)
    (bn_latent): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (decoder): CAEDecoder(
    (latent_linear): Linear(in_features=100, out_features=128, bias=True)
    (bn_latent): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (deconv1): ConvTranspose2d(8, 16, kernel_size=(2, 2), stride=(2, 2))
    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (deconv2): ConvTranspose2d(16, 32, kernel_size=(2, 2), stride=(2, 2))
    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (deconv3): ConvTranspose2d(32, 64, kernel_size=(2, 2), stride=(2, 2))
    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (deconv4): ConvTranspose2d(64, 1, kernel_size=(2, 2), stride=(2, 2))
    (bn4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
[2019-06-02 20:08:29] - Model loss: 4.916571924695745e-06
