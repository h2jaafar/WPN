[2019-05-22 14:09:21] - Starting holdout training: {
	data_features: [],
	data_labels: [],
	data_single_features: ['global_map'],
	data_single_labels: ['global_map'],
	epochs: 100,
	loss: L1Loss(),
	optimizer: <function f.<locals>.<lambda> at 0x7f3572e23d90>,
	validation_ratio: 0.2,
	test_ratio: 0.2,
	save_name: caelstm_section_cae,
	training_data: training_uniform_random_fill_10000_block_map_10000,
	batch_size: 50,
	use_mnist_instead: False,
	mnist_size: None,
	with_skip_connections: True,
	in_dim: [64, 64],
	latent_dim: 100,
}

[2019-05-22 14:09:21] - Starting data pre processing
[2019-05-22 14:09:23] - Cache hit, training data loaded from cache
[2019-05-22 14:09:23] - Finished data pre processing 

[2019-05-22 14:09:23] - Training: <class 'algorithms.lstm.LSTM_CAE_tile_by_tile.CAE'>
[2019-05-22 14:09:28] - Training 	 Epoch: 0 	 Loss: 43.026846
[2019-05-22 14:09:30] - Validation 	 Epoch: 0 	 Loss: 2.919186

[2019-05-22 14:09:36] - Training 	 Epoch: 1 	 Loss: 5.156279
[2019-05-22 14:09:38] - Validation 	 Epoch: 1 	 Loss: 1.026465

[2019-05-22 14:09:43] - Training 	 Epoch: 2 	 Loss: 2.262591
[2019-05-22 14:09:45] - Validation 	 Epoch: 2 	 Loss: 0.544071

[2019-05-22 14:09:51] - Training 	 Epoch: 3 	 Loss: 1.311464
[2019-05-22 14:09:53] - Validation 	 Epoch: 3 	 Loss: 0.345459

[2019-05-22 14:09:58] - Training 	 Epoch: 4 	 Loss: 0.864531
[2019-05-22 14:10:00] - Validation 	 Epoch: 4 	 Loss: 0.237032

[2019-05-22 14:10:06] - Training 	 Epoch: 5 	 Loss: 0.614180
[2019-05-22 14:10:08] - Validation 	 Epoch: 5 	 Loss: 0.173444

[2019-05-22 14:10:13] - Training 	 Epoch: 6 	 Loss: 0.458175
[2019-05-22 14:10:15] - Validation 	 Epoch: 6 	 Loss: 0.130856

[2019-05-22 14:10:20] - Training 	 Epoch: 7 	 Loss: 0.353720
[2019-05-22 14:10:22] - Validation 	 Epoch: 7 	 Loss: 0.103645

[2019-05-22 14:10:28] - Training 	 Epoch: 8 	 Loss: 0.280071
[2019-05-22 14:10:30] - Validation 	 Epoch: 8 	 Loss: 0.082821

[2019-05-22 14:10:35] - Training 	 Epoch: 9 	 Loss: 0.226078
[2019-05-22 14:10:37] - Validation 	 Epoch: 9 	 Loss: 0.067322

[2019-05-22 14:10:43] - Training 	 Epoch: 10 	 Loss: 0.185277
[2019-05-22 14:10:45] - Validation 	 Epoch: 10 	 Loss: 0.055632

[2019-05-22 14:10:50] - Training 	 Epoch: 11 	 Loss: 0.153690
[2019-05-22 14:10:52] - Validation 	 Epoch: 11 	 Loss: 0.046377

[2019-05-22 14:10:57] - Training 	 Epoch: 12 	 Loss: 0.128750
[2019-05-22 14:10:59] - Validation 	 Epoch: 12 	 Loss: 0.038888

[2019-05-22 14:11:05] - Training 	 Epoch: 13 	 Loss: 0.108738
[2019-05-22 14:11:07] - Validation 	 Epoch: 13 	 Loss: 0.032777

[2019-05-22 14:11:12] - Training 	 Epoch: 14 	 Loss: 0.092460
[2019-05-22 14:11:14] - Validation 	 Epoch: 14 	 Loss: 0.028075

[2019-05-22 14:11:19] - Training 	 Epoch: 15 	 Loss: 0.079067
[2019-05-22 14:11:21] - Validation 	 Epoch: 15 	 Loss: 0.024115

[2019-05-22 14:11:27] - Training 	 Epoch: 16 	 Loss: 0.067941
[2019-05-22 14:11:28] - Validation 	 Epoch: 16 	 Loss: 0.020803

[2019-05-22 14:11:34] - Training 	 Epoch: 17 	 Loss: 0.058621
[2019-05-22 14:11:36] - Validation 	 Epoch: 17 	 Loss: 0.017930

[2019-05-22 14:11:41] - Training 	 Epoch: 18 	 Loss: 0.050757
[2019-05-22 14:11:43] - Validation 	 Epoch: 18 	 Loss: 0.015557

[2019-05-22 14:11:48] - Training 	 Epoch: 19 	 Loss: 0.044081
[2019-05-22 14:11:50] - Validation 	 Epoch: 19 	 Loss: 0.013553

[2019-05-22 14:11:56] - Training 	 Epoch: 20 	 Loss: 0.038384
[2019-05-22 14:11:58] - Validation 	 Epoch: 20 	 Loss: 0.011780

[2019-05-22 14:12:03] - Training 	 Epoch: 21 	 Loss: 0.033499
[2019-05-22 14:12:05] - Validation 	 Epoch: 21 	 Loss: 0.010285

[2019-05-22 14:12:10] - Training 	 Epoch: 22 	 Loss: 0.029293
[2019-05-22 14:12:12] - Validation 	 Epoch: 22 	 Loss: 0.008986

[2019-05-22 14:12:18] - Training 	 Epoch: 23 	 Loss: 0.025659
[2019-05-22 14:12:20] - Validation 	 Epoch: 23 	 Loss: 0.007881

[2019-05-22 14:12:25] - Training 	 Epoch: 24 	 Loss: 0.022510
[2019-05-22 14:12:27] - Validation 	 Epoch: 24 	 Loss: 0.006921

[2019-05-22 14:12:32] - Training 	 Epoch: 25 	 Loss: 0.019773
[2019-05-22 14:12:34] - Validation 	 Epoch: 25 	 Loss: 0.006079

[2019-05-22 14:12:40] - Training 	 Epoch: 26 	 Loss: 0.017389
[2019-05-22 14:12:42] - Validation 	 Epoch: 26 	 Loss: 0.005352

[2019-05-22 14:12:47] - Training 	 Epoch: 27 	 Loss: 0.015308
[2019-05-22 14:12:49] - Validation 	 Epoch: 27 	 Loss: 0.004711

[2019-05-22 14:12:54] - Training 	 Epoch: 28 	 Loss: 0.013487
[2019-05-22 14:12:56] - Validation 	 Epoch: 28 	 Loss: 0.004162

[2019-05-22 14:13:01] - Training 	 Epoch: 29 	 Loss: 0.011893
[2019-05-22 14:13:03] - Validation 	 Epoch: 29 	 Loss: 0.003653

[2019-05-22 14:13:09] - Training 	 Epoch: 30 	 Loss: 0.010494
[2019-05-22 14:13:11] - Validation 	 Epoch: 30 	 Loss: 0.003228

[2019-05-22 14:13:16] - Training 	 Epoch: 31 	 Loss: 0.009265
[2019-05-22 14:13:18] - Validation 	 Epoch: 31 	 Loss: 0.002846

[2019-05-22 14:13:24] - Training 	 Epoch: 32 	 Loss: 0.008185
[2019-05-22 14:13:26] - Validation 	 Epoch: 32 	 Loss: 0.002522

[2019-05-22 14:13:31] - Training 	 Epoch: 33 	 Loss: 0.007233
[2019-05-22 14:13:33] - Validation 	 Epoch: 33 	 Loss: 0.002222

[2019-05-22 14:13:38] - Training 	 Epoch: 34 	 Loss: 0.006396
[2019-05-22 14:13:40] - Validation 	 Epoch: 34 	 Loss: 0.001964

[2019-05-22 14:13:45] - Training 	 Epoch: 35 	 Loss: 0.005657
[2019-05-22 14:13:47] - Validation 	 Epoch: 35 	 Loss: 0.001737

[2019-05-22 14:13:53] - Training 	 Epoch: 36 	 Loss: 0.005005
[2019-05-22 14:13:55] - Validation 	 Epoch: 36 	 Loss: 0.001538

[2019-05-22 14:14:00] - Training 	 Epoch: 37 	 Loss: 0.004429
[2019-05-22 14:14:02] - Validation 	 Epoch: 37 	 Loss: 0.001362

[2019-05-22 14:14:07] - Training 	 Epoch: 38 	 Loss: 0.003921
[2019-05-22 14:14:09] - Validation 	 Epoch: 38 	 Loss: 0.001204

[2019-05-22 14:14:14] - Training 	 Epoch: 39 	 Loss: 0.003472
[2019-05-22 14:14:16] - Validation 	 Epoch: 39 	 Loss: 0.001065

[2019-05-22 14:14:22] - Training 	 Epoch: 40 	 Loss: 0.003075
[2019-05-22 14:14:24] - Validation 	 Epoch: 40 	 Loss: 0.000944

[2019-05-22 14:14:29] - Training 	 Epoch: 41 	 Loss: 0.002724
[2019-05-22 14:14:31] - Validation 	 Epoch: 41 	 Loss: 0.000836

[2019-05-22 14:14:36] - Training 	 Epoch: 42 	 Loss: 0.002413
[2019-05-22 14:14:39] - Validation 	 Epoch: 42 	 Loss: 0.000740

[2019-05-22 14:14:44] - Training 	 Epoch: 43 	 Loss: 0.002138
[2019-05-22 14:14:46] - Validation 	 Epoch: 43 	 Loss: 0.000656

[2019-05-22 14:14:52] - Training 	 Epoch: 44 	 Loss: 0.001894
[2019-05-22 14:14:54] - Validation 	 Epoch: 44 	 Loss: 0.000580

[2019-05-22 14:14:59] - Training 	 Epoch: 45 	 Loss: 0.001679
[2019-05-22 14:15:01] - Validation 	 Epoch: 45 	 Loss: 0.000514

[2019-05-22 14:15:06] - Training 	 Epoch: 46 	 Loss: 0.001488
[2019-05-22 14:15:08] - Validation 	 Epoch: 46 	 Loss: 0.000456

[2019-05-22 14:15:14] - Training 	 Epoch: 47 	 Loss: 0.001319
[2019-05-22 14:15:16] - Validation 	 Epoch: 47 	 Loss: 0.000404

[2019-05-22 14:15:21] - Training 	 Epoch: 48 	 Loss: 0.001169
[2019-05-22 14:15:23] - Validation 	 Epoch: 48 	 Loss: 0.000358

[2019-05-22 14:15:28] - Training 	 Epoch: 49 	 Loss: 0.001037
[2019-05-22 14:15:30] - Validation 	 Epoch: 49 	 Loss: 0.000317

[2019-05-22 14:15:35] - Training 	 Epoch: 50 	 Loss: 0.000919
[2019-05-22 14:15:37] - Validation 	 Epoch: 50 	 Loss: 0.000281

[2019-05-22 14:15:43] - Training 	 Epoch: 51 	 Loss: 0.000815
[2019-05-22 14:15:45] - Validation 	 Epoch: 51 	 Loss: 0.000249

[2019-05-22 14:15:50] - Training 	 Epoch: 52 	 Loss: 0.000722
[2019-05-22 14:15:52] - Validation 	 Epoch: 52 	 Loss: 0.000220

[2019-05-22 14:15:58] - Training 	 Epoch: 53 	 Loss: 0.000641
[2019-05-22 14:16:00] - Validation 	 Epoch: 53 	 Loss: 0.000196

[2019-05-22 14:16:05] - Training 	 Epoch: 54 	 Loss: 0.000568
[2019-05-22 14:16:07] - Validation 	 Epoch: 54 	 Loss: 0.000174

[2019-05-22 14:16:12] - Training 	 Epoch: 55 	 Loss: 0.000504
[2019-05-22 14:16:14] - Validation 	 Epoch: 55 	 Loss: 0.000153

[2019-05-22 14:16:20] - Training 	 Epoch: 56 	 Loss: 0.000447
[2019-05-22 14:16:21] - Validation 	 Epoch: 56 	 Loss: 0.000136

[2019-05-22 14:16:27] - Training 	 Epoch: 57 	 Loss: 0.000396
[2019-05-22 14:16:29] - Validation 	 Epoch: 57 	 Loss: 0.000121

[2019-05-22 14:16:34] - Training 	 Epoch: 58 	 Loss: 0.000351
[2019-05-22 14:16:36] - Validation 	 Epoch: 58 	 Loss: 0.000107

[2019-05-22 14:16:41] - Training 	 Epoch: 59 	 Loss: 0.000312
[2019-05-22 14:16:43] - Validation 	 Epoch: 59 	 Loss: 0.000094

[2019-05-22 14:16:48] - Training 	 Epoch: 60 	 Loss: 0.000276
[2019-05-22 14:16:50] - Validation 	 Epoch: 60 	 Loss: 0.000085

[2019-05-22 14:16:56] - Training 	 Epoch: 61 	 Loss: 0.000245
[2019-05-22 14:16:58] - Validation 	 Epoch: 61 	 Loss: 0.000075

[2019-05-22 14:17:03] - Training 	 Epoch: 62 	 Loss: 0.000217
[2019-05-22 14:17:05] - Validation 	 Epoch: 62 	 Loss: 0.000066

[2019-05-22 14:17:10] - Training 	 Epoch: 63 	 Loss: 0.000193
[2019-05-22 14:17:12] - Validation 	 Epoch: 63 	 Loss: 0.000058

[2019-05-22 14:17:18] - Training 	 Epoch: 64 	 Loss: 0.000171
[2019-05-22 14:17:20] - Validation 	 Epoch: 64 	 Loss: 0.000053

[2019-05-22 14:17:25] - Training 	 Epoch: 65 	 Loss: 0.000152
[2019-05-22 14:17:27] - Validation 	 Epoch: 65 	 Loss: 0.000045

[2019-05-22 14:17:32] - Training 	 Epoch: 66 	 Loss: 0.000135
[2019-05-22 14:17:34] - Validation 	 Epoch: 66 	 Loss: 0.000040

[2019-05-22 14:17:39] - Training 	 Epoch: 67 	 Loss: 0.000119
[2019-05-22 14:17:41] - Validation 	 Epoch: 67 	 Loss: 0.000035

[2019-05-22 14:17:47] - Training 	 Epoch: 68 	 Loss: 0.000106
[2019-05-22 14:17:49] - Validation 	 Epoch: 68 	 Loss: 0.000032

[2019-05-22 14:17:54] - Training 	 Epoch: 69 	 Loss: 0.000094
[2019-05-22 14:17:56] - Validation 	 Epoch: 69 	 Loss: 0.000028

[2019-05-22 14:18:01] - Training 	 Epoch: 70 	 Loss: 0.000083
[2019-05-22 14:18:03] - Validation 	 Epoch: 70 	 Loss: 0.000027

[2019-05-22 14:18:08] - Training 	 Epoch: 71 	 Loss: 0.000074
[2019-05-22 14:18:10] - Validation 	 Epoch: 71 	 Loss: 0.000022

[2019-05-22 14:18:16] - Training 	 Epoch: 72 	 Loss: 0.000065
[2019-05-22 14:18:18] - Validation 	 Epoch: 72 	 Loss: 0.000019

[2019-05-22 14:18:23] - Training 	 Epoch: 73 	 Loss: 0.000058
[2019-05-22 14:18:25] - Validation 	 Epoch: 73 	 Loss: 0.000018

[2019-05-22 14:18:30] - Training 	 Epoch: 74 	 Loss: 0.000052
[2019-05-22 14:18:32] - Validation 	 Epoch: 74 	 Loss: 0.000015

[2019-05-22 14:18:38] - Training 	 Epoch: 75 	 Loss: 0.000046
[2019-05-22 14:18:40] - Validation 	 Epoch: 75 	 Loss: 0.000013

[2019-05-22 14:18:45] - Training 	 Epoch: 76 	 Loss: 0.000041
[2019-05-22 14:18:47] - Validation 	 Epoch: 76 	 Loss: 0.000013

[2019-05-22 14:18:52] - Training 	 Epoch: 77 	 Loss: 0.000036
[2019-05-22 14:18:54] - Validation 	 Epoch: 77 	 Loss: 0.000010

[2019-05-22 14:18:59] - Training 	 Epoch: 78 	 Loss: 0.000032
[2019-05-22 14:19:01] - Validation 	 Epoch: 78 	 Loss: 0.000009

[2019-05-22 14:19:07] - Training 	 Epoch: 79 	 Loss: 0.000028
[2019-05-22 14:19:08] - Validation 	 Epoch: 79 	 Loss: 0.000009

[2019-05-22 14:19:14] - Training 	 Epoch: 80 	 Loss: 0.000026
[2019-05-22 14:19:16] - Validation 	 Epoch: 80 	 Loss: 0.000009

[2019-05-22 14:19:21] - Training 	 Epoch: 81 	 Loss: 0.000023
[2019-05-22 14:19:23] - Validation 	 Epoch: 81 	 Loss: 0.000007

[2019-05-22 14:19:28] - Training 	 Epoch: 82 	 Loss: 0.000019
[2019-05-22 14:19:30] - Validation 	 Epoch: 82 	 Loss: 0.000005

[2019-05-22 14:19:35] - Training 	 Epoch: 83 	 Loss: 0.000016
[2019-05-22 14:19:37] - Validation 	 Epoch: 83 	 Loss: 0.000005

[2019-05-22 14:19:43] - Training 	 Epoch: 84 	 Loss: 0.000015
[2019-05-22 14:19:44] - Validation 	 Epoch: 84 	 Loss: 0.000005

[2019-05-22 14:19:50] - Training 	 Epoch: 85 	 Loss: 0.000014
[2019-05-22 14:19:52] - Validation 	 Epoch: 85 	 Loss: 0.000004

[2019-05-22 14:19:57] - Training 	 Epoch: 86 	 Loss: 0.000014
[2019-05-22 14:19:59] - Validation 	 Epoch: 86 	 Loss: 0.000005

[2019-05-22 14:20:05] - Training 	 Epoch: 87 	 Loss: 0.000013
[2019-05-22 14:20:07] - Validation 	 Epoch: 87 	 Loss: 0.000004

[2019-05-22 14:20:12] - Training 	 Epoch: 88 	 Loss: 0.000012
[2019-05-22 14:20:14] - Validation 	 Epoch: 88 	 Loss: 0.000004

[2019-05-22 14:20:19] - Training 	 Epoch: 89 	 Loss: 0.000009
[2019-05-22 14:20:21] - Validation 	 Epoch: 89 	 Loss: 0.000003

[2019-05-22 14:20:27] - Training 	 Epoch: 90 	 Loss: 0.000006
[2019-05-22 14:20:28] - Validation 	 Epoch: 90 	 Loss: 0.000001

[2019-05-22 14:20:34] - Training 	 Epoch: 91 	 Loss: 0.000004
[2019-05-22 14:20:36] - Validation 	 Epoch: 91 	 Loss: 0.000000

[2019-05-22 14:20:41] - Training 	 Epoch: 92 	 Loss: 0.000003
[2019-05-22 14:20:43] - Validation 	 Epoch: 92 	 Loss: 0.000000

[2019-05-22 14:20:48] - Training 	 Epoch: 93 	 Loss: 0.000002
[2019-05-22 14:20:50] - Validation 	 Epoch: 93 	 Loss: 0.000000

[2019-05-22 14:20:55] - Training 	 Epoch: 94 	 Loss: 0.000002
[2019-05-22 14:20:57] - Validation 	 Epoch: 94 	 Loss: 0.000000

[2019-05-22 14:21:02] - Training 	 Epoch: 95 	 Loss: 0.000001
[2019-05-22 14:21:04] - Validation 	 Epoch: 95 	 Loss: 0.000000

[2019-05-22 14:21:10] - Training 	 Epoch: 96 	 Loss: 0.000001
[2019-05-22 14:21:12] - Validation 	 Epoch: 96 	 Loss: 0.000000

[2019-05-22 14:21:17] - Training 	 Epoch: 97 	 Loss: 0.000001
[2019-05-22 14:21:19] - Validation 	 Epoch: 97 	 Loss: 0.000000

[2019-05-22 14:21:25] - Training 	 Epoch: 98 	 Loss: 0.000001
[2019-05-22 14:21:26] - Validation 	 Epoch: 98 	 Loss: 0.000000

[2019-05-22 14:21:32] - Training 	 Epoch: 99 	 Loss: 0.000001
[2019-05-22 14:21:34] - Validation 	 Epoch: 99 	 Loss: 0.000000


[2019-05-22 14:21:34] - Evaluation: <class 'algorithms.lstm.LSTM_CAE_tile_by_tile.CAE'>
[2019-05-22 14:21:36] - Evaluation 	 Epoch: 0 	 Loss: 0.000000

[2019-05-22 14:21:36] - Saved model as caelstm_section_cae_training_uniform_random_fill_10000_block_map_10000_model
[2019-05-22 14:21:36] - Model: CAE(
  (encoder): CAEEncoder(
    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (latent_linear): Linear(in_features=128, out_features=100, bias=True)
    (bn_latent): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (decoder): CAEDecoder(
    (latent_linear): Linear(in_features=100, out_features=128, bias=True)
    (bn_latent): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (deconv1): ConvTranspose2d(8, 16, kernel_size=(2, 2), stride=(2, 2))
    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (deconv2): ConvTranspose2d(16, 32, kernel_size=(2, 2), stride=(2, 2))
    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (deconv3): ConvTranspose2d(32, 64, kernel_size=(2, 2), stride=(2, 2))
    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (deconv4): ConvTranspose2d(64, 1, kernel_size=(2, 2), stride=(2, 2))
    (bn4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
[2019-05-22 14:21:36] - Model loss: 2.46858690607088e-09
